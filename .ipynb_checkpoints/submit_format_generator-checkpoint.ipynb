{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path_dataset):\n",
    "    \"\"\"Load dataset into memory from text file\"\"\"\n",
    "    dataset = []\n",
    "    with open(path_dataset) as f:\n",
    "        words, tags = [], []\n",
    "        # Each line of the file corresponds to one word and tag\n",
    "        for line in f:\n",
    "            if line != '\\n':\n",
    "                line = line.strip('\\n')\n",
    "                if len(line.split()) > 0:\n",
    "                    word = line.split()[0]\n",
    "                    #tag = line.split()[-1]\n",
    "                else:\n",
    "                    word = line.split()[0]\n",
    "                    # print(line)\n",
    "                    continue\n",
    "                try:\n",
    "                    if len(word) > 0:\n",
    "                        word = str(word)\n",
    "                        words.append(word)\n",
    "                        #tags.append(tag)\n",
    "                except Exception as e:\n",
    "                    print('An exception was raised, skipping a word: {}'.format(e))\n",
    "            else:\n",
    "                if len(words) > 0:\n",
    "                    #assert len(words) == len(tags)\n",
    "                    dataset.append((words))\n",
    "                    words, tags = [], []\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(dataset, save_dir,file_name):\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    print('Saving in {}...'.format(save_dir))\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Export the dataset\n",
    "    with open(os.path.join(save_dir, file_name), 'w') as file_sentences:\n",
    "        for sent in dataset:\n",
    "            for word in sent:\n",
    "                file_sentences.writelines('%s\\n' %word)\n",
    "            file_sentences.writelines('\\n')\n",
    "            #file_tags.write('{}\\n'.format(' '.join(tags)))\n",
    "        file_sentences.writelines('\\n')\n",
    "        file_sentences.writelines('\\n')\n",
    "    print('- done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'submission_Conll'\n",
    "import glob\n",
    "filenames = glob.glob('output_data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tags_files = []\n",
    "for filename in filenames:\n",
    "    pred_tags_file = load_dataset(filename)\n",
    "    pred_tags_files.append(pred_tags_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "root_dir = 'data/meddo/test_data/Conll_Format/'\n",
    "for filename in filenames:\n",
    "    pred_tags_file = load_dataset(filename)\n",
    "    re_name = filename.split('/')[-1]\n",
    "    words_file = load_dataset(root_dir + re_name )\n",
    "    for i in range(len(pred_tags_file)):\n",
    "        for j in range(len(pred_tags_file[i])):\n",
    "            words_file[i][j] = words_file[i][j]+\"\\t\"+pred_tags_file[i][j]\n",
    "    save_dataset(words_file,save_dir,re_name)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output_data/casos_clinicos_profesiones230.txt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_file = glob.glob(\"./data/meddo/interactive/sentences/*.txt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conll(sentences_file, filenames):\n",
    "    with open(sentences_file) as f, open(filenames) as q:\n",
    "        assert sentences_file.split(\"/\")[-1] == filenames.split(\"/\")[-1]\n",
    "        words, tags, comb_str = [], [], []\n",
    "        for line_sentence, line_tags in zip(f,q):\n",
    "            try:\n",
    "                assert len(space_remover(line_sentence)) == len(space_remover(line_tags))\n",
    "                words.append(space_remover(line_sentence))\n",
    "                tags.append(space_remover(line_tags))\n",
    "            except:\n",
    "                token_list = space_remover(line_sentence)\n",
    "                tag_list = space_remover(line_tags)\n",
    "                if len(token_list) <= 0:\n",
    "                    continue\n",
    "                for i in range(len(token_list) - len(tag_list)):\n",
    "                    tag_list.append('O')\n",
    "                if tag_list[-1] == '\\n':\n",
    "                    tag_list = tag_list[:-1]\n",
    "                print(len(tag_list), len(token_list))\n",
    "                assert len(tag_list) == len(token_list)\n",
    "                words.append(token_list)\n",
    "                tags.append(tag_list)\n",
    "                #print(\"the following file name is wrong\"+ str(sentences_file.split(\"/\")[-1]))\n",
    "        for tokens,tag in zip(words,tags):\n",
    "            for token,t in zip(tokens, tag):\n",
    "                comb_str.append(token+ \"\\t\" + t)\n",
    "\n",
    "        with open(\"./temp/\"+sentences_file.split(\"/\")[-1], 'w') as r:\n",
    "            for item in comb_str:\n",
    "                r.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/meddo/interactive/sentences/casos_clinicos_profesiones230.txt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def space_remover(s):\n",
    "    out = re.findall(r'\\S+|\\n',s)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_conll(sentences_file[130], filenames[130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 189\n",
      "93 92\n",
      "78 77\n",
      "25 24\n",
      "73 72\n",
      "77 76\n",
      "228 227\n",
      "166 165\n",
      "41 40\n",
      "41 40\n",
      "184 183\n",
      "78 77\n",
      "105 104\n",
      "64 63\n",
      "18 17\n",
      "131 130\n",
      "44 43\n",
      "51 50\n",
      "118 117\n",
      "104 103\n",
      "16 15\n",
      "44 43\n",
      "5 4\n",
      "82 81\n",
      "6 5\n",
      "54 53\n",
      "46 45\n",
      "8 7\n",
      "361 361\n",
      "20 19\n",
      "5 4\n",
      "27 26\n",
      "187 186\n",
      "175 174\n",
      "178 177\n",
      "53 52\n",
      "9 8\n",
      "12 11\n",
      "12 11\n",
      "134 133\n",
      "38 37\n",
      "44 43\n",
      "131 130\n",
      "76 75\n",
      "67 66\n",
      "90 89\n",
      "93 92\n",
      "45 44\n",
      "35 34\n",
      "7 6\n",
      "37 36\n",
      "178 177\n",
      "34 33\n",
      "209 208\n",
      "59 58\n",
      "34 33\n",
      "202 201\n",
      "456 456\n",
      "413 413\n",
      "146 145\n",
      "104 103\n",
      "16 15\n",
      "197 196\n",
      "13 12\n",
      "50 49\n",
      "10 9\n",
      "28 27\n",
      "155 154\n",
      "555 555\n",
      "38 37\n",
      "45 44\n",
      "28 27\n",
      "63 62\n",
      "89 88\n",
      "146 145\n",
      "197 196\n",
      "407 407\n",
      "147 146\n",
      "31 30\n",
      "16 15\n",
      "37 36\n",
      "115 114\n",
      "31 30\n",
      "88 87\n",
      "66 65\n",
      "436 436\n",
      "110 109\n",
      "27 26\n",
      "82 81\n",
      "33 32\n",
      "3 2\n",
      "161 160\n",
      "127 126\n",
      "208 207\n",
      "65 64\n",
      "71 70\n",
      "123 122\n",
      "106 105\n",
      "12 11\n",
      "100 99\n",
      "185 184\n",
      "196 195\n",
      "52 51\n",
      "37 36\n",
      "70 69\n",
      "381 381\n",
      "20 19\n",
      "144 143\n",
      "70 69\n",
      "299 298\n",
      "27 26\n",
      "28 27\n",
      "51 50\n",
      "916 916\n",
      "387 387\n",
      "22 21\n",
      "791 791\n",
      "15 14\n",
      "27 26\n",
      "134 133\n",
      "12 11\n",
      "17 16\n",
      "502 502\n",
      "192 191\n",
      "92 91\n",
      "223 222\n",
      "479 479\n",
      "699 699\n",
      "176 175\n",
      "215 214\n",
      "120 119\n",
      "37 36\n",
      "113 112\n",
      "69 68\n",
      "632 632\n",
      "54 53\n",
      "201 200\n",
      "26 25\n",
      "343 343\n",
      "136 135\n",
      "64 63\n",
      "83 82\n",
      "54 53\n",
      "71 70\n",
      "112 111\n",
      "34 33\n",
      "134 133\n",
      "210 209\n",
      "149 148\n",
      "4 3\n",
      "350 350\n",
      "8 7\n",
      "54 53\n",
      "138 137\n",
      "508 508\n",
      "59 58\n",
      "68 67\n",
      "187 186\n",
      "102 101\n",
      "174 173\n",
      "3 2\n",
      "136 135\n",
      "68 67\n",
      "31 30\n",
      "215 214\n",
      "73 72\n",
      "310 309\n",
      "9 8\n",
      "166 165\n",
      "184 183\n",
      "390 389\n",
      "12 11\n",
      "31 30\n",
      "573 573\n",
      "13 12\n",
      "54 53\n",
      "61 60\n",
      "19 18\n",
      "419 419\n",
      "329 328\n",
      "207 206\n",
      "12 11\n",
      "14 13\n",
      "576 576\n",
      "84 83\n",
      "30 29\n",
      "212 211\n",
      "300 299\n",
      "163 162\n",
      "33 32\n",
      "480 480\n",
      "33 32\n",
      "191 190\n",
      "170 169\n",
      "46 45\n",
      "103 102\n",
      "117 116\n",
      "6 5\n",
      "220 219\n",
      "135 134\n",
      "37 36\n",
      "43 42\n",
      "346 346\n",
      "42 41\n",
      "143 142\n",
      "77 76\n",
      "20 19\n",
      "44 43\n",
      "282 281\n",
      "18 17\n",
      "19 18\n",
      "466 466\n",
      "8 7\n",
      "34 33\n",
      "27 27\n",
      "19 19\n",
      "47 46\n",
      "18 17\n",
      "52 51\n",
      "55 54\n",
      "103 102\n",
      "3 2\n",
      "18 17\n",
      "4 3\n",
      "34 33\n",
      "252 251\n",
      "37 36\n",
      "104 103\n",
      "331 331\n",
      "239 238\n",
      "56 55\n",
      "90 89\n",
      "50 49\n",
      "38 37\n",
      "9 8\n",
      "217 216\n",
      "35 34\n",
      "16 15\n",
      "259 258\n",
      "15 14\n",
      "78 77\n",
      "59 58\n",
      "435 435\n",
      "132 131\n",
      "191 190\n",
      "29 28\n",
      "40 39\n",
      "62 61\n",
      "52 51\n",
      "19 18\n",
      "114 113\n",
      "137 136\n",
      "63 62\n",
      "19 18\n",
      "134 133\n",
      "15 14\n",
      "78 77\n",
      "16 15\n",
      "39 38\n",
      "42 41\n",
      "681 681\n",
      "359 359\n",
      "78 77\n",
      "228 227\n",
      "13 12\n",
      "46 45\n",
      "90 89\n",
      "499 499\n",
      "48 47\n",
      "58 57\n",
      "69 68\n",
      "64 63\n",
      "76 75\n",
      "22 21\n",
      "201 200\n",
      "41 40\n",
      "70 69\n",
      "8 7\n",
      "566 566\n",
      "63 62\n",
      "449 449\n",
      "122 121\n",
      "129 128\n",
      "5 4\n",
      "43 42\n",
      "7 6\n",
      "173 172\n",
      "19 18\n",
      "5 4\n",
      "6 5\n",
      "597 597\n",
      "563 563\n",
      "108 107\n",
      "307 306\n",
      "17 16\n",
      "89 88\n",
      "644 644\n",
      "88 87\n",
      "12 11\n",
      "85 84\n",
      "31 30\n",
      "453 453\n",
      "44 43\n",
      "37 36\n",
      "128 127\n",
      "80 79\n",
      "32 31\n",
      "51 50\n",
      "183 182\n",
      "5 4\n",
      "28 27\n",
      "37 36\n",
      "48 47\n",
      "21 20\n",
      "7 6\n",
      "32 31\n",
      "15 14\n",
      "66 65\n",
      "555 555\n",
      "97 96\n",
      "285 284\n",
      "7 6\n",
      "59 58\n",
      "262 261\n",
      "169 168\n",
      "249 248\n",
      "34 33\n",
      "59 58\n",
      "37 36\n",
      "55 54\n",
      "81 80\n",
      "261 261\n",
      "756 756\n",
      "164 163\n",
      "258 257\n",
      "51 50\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for sentences_f, file_n in zip(sentences_file,filenames):\n",
    "    generate_conll(sentences_f, file_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_class = 'mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es'\n",
    "# from transformers import BertTokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained(bert_class, do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
